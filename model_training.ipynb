{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YuNet Face Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the YuNet face detector\n",
    "IMG_SIZE = 320\n",
    "# yunet_path = './yunet_model/face_detection_yunet_2023mar.onnx'\n",
    "# detector = cv2.FaceDetectorYN_create(yunet_path, \"\", (IMG_SIZE, IMG_SIZE), score_threshold=0.5)\n",
    "\n",
    "# Directory where images are stored\n",
    "# image_dir = 'datasets/Acne_Detection/'\n",
    "# output_dir = 'datasets/iso_Acne_Detection/'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "# os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all image files in the directory\n",
    "all_images = [file for file in os.listdir(image_dir) if file.endswith(('.jpg', '.jpeg', 'png'))]\n",
    "\n",
    "# Calculate the number of images to read (1/8 of total)\n",
    "# num_images_to_read = max(1, len(all_images) // 8)\n",
    "\n",
    "# Randomly sample the specified number of images\n",
    "# sampled_images = random.sample(all_images, num_images_to_read)\n",
    "\n",
    "# Count missed detections\n",
    "missed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each image in the directory\n",
    "for filename in all_images:\n",
    "    image_path = os.path.join(image_dir, filename)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Resize the image to the expected input size\n",
    "    resized_image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # Detect faces in the image\n",
    "    faces = detector.detect(resized_image)\n",
    "\n",
    "    # Check if faces were detected\n",
    "    if faces[1] is None: \n",
    "        missed += 1\n",
    "    else:\n",
    "        # Isolate detected faces\n",
    "        for face in faces[1]:  \n",
    "            x, y, w, h = int(face[0]), int(face[1]), int(face[2]), int(face[3])  \n",
    "            x = max(0, x)\n",
    "            y = max(0, y)\n",
    "            w = min(w, IMG_SIZE-x)\n",
    "            h = min(h, IMG_SIZE-y)\n",
    "\n",
    "            #crop the face \n",
    "            cropped_face = resized_image[y:y+h, x:x+w]\n",
    "\n",
    "            # Save the cropped image\n",
    "            output_path = os.path.join(output_dir, filename)\n",
    "            cv2.imwrite(output_path, cropped_face)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = len(all_images)\n",
    "print(f\"Missed {np.round(missed/sample_size * 100, 2)} % of images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv8 Object Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"models/yolov8n.pt\")\n",
    "model.train(data=\"datasets/kaggle-acne/data.yaml\", epochs=100, imgsz=320, batch=4, conf=0.4, iou=0.3, nms=True, max_det=10, hsv_h=0.03, hsv_s=0.9, hsv_v=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet-50 Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.src.applications.resnet import ResNet50\n",
    "from keras.src.layers import Dense, GlobalAveragePooling2D, Flatten\n",
    "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
    "from keras.src.optimizers import Adam\n",
    "from keras.src.models import Model\n",
    "from keras.src.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 320\n",
    "IMAGE_SHAPE = [IMG_SIZE, IMG_SIZE, 3]\n",
    "base_resnet_model = ResNet50(input_shape=IMAGE_SHAPE, weights='imagenet', include_top=False)\n",
    "# print(base_resnet_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_resnet_model.trainable = False\n",
    "# print(base_resnet_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'datasets/roboflow_acne/train'\n",
    "test_path = 'datasets/roboflow_acne/test'\n",
    "valid_path = 'datasets/roboflow_acne/valid'\n",
    "\n",
    "x = base_resnet_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(4, activation='softmax')(x)\n",
    "\n",
    "final_resnet_model = Model(inputs = base_resnet_model.input, outputs=x)\n",
    "print(final_resnet_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "final_resnet_model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "  rescale=1.0/255,\n",
    "  rotation_range=20,\n",
    "  width_shift_range=0.2,\n",
    "  height_shift_range=0.2,\n",
    "  horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "  rescale=1.0/255\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(\n",
    "  train_path,\n",
    "  target_size=(IMG_SIZE, IMG_SIZE),\n",
    "  batch_size=16,\n",
    "  class_mode='categorical'\n",
    ")\n",
    "\n",
    "valid_set = test_datagen.flow_from_directory(\n",
    "  valid_path,\n",
    "  target_size=(IMG_SIZE, IMG_SIZE),\n",
    "  batch_size=16,\n",
    "  class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "  test_path,\n",
    "  target_size=(IMG_SIZE, IMG_SIZE),\n",
    "  batch_size=16,\n",
    "  class_mode='categorical',\n",
    "  shuffle=False\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "  ModelCheckpoint('models/best.keras', verbose=True, save_best_only=True, monitor='val_accuracy'),\n",
    "  ReduceLROnPlateau(monitor='val_accuracy', patience=10, factor=0.1, verbose=True, min_lr=0.00001),\n",
    "  EarlyStopping(monitor='val_accuracy', patience=30, verbose=True)\n",
    "]\n",
    "\n",
    "final_resnet_model.fit(\n",
    "  train_set,\n",
    "  validation_data=valid_set,\n",
    "  epochs=200,\n",
    "  callbacks=callbacks,\n",
    "  steps_per_epoch=len(train_set),\n",
    "  validation_steps=len(valid_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_resnet_model = tf.keras.models.load_model('models/best.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = best_resnet_model.evaluate(test_set, steps=len(test_set))\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_accuracy = best_resnet_model.evaluate(train_set, steps=len(train_set))\n",
    "print(f\"Train Loss: {train_loss}\")\n",
    "print(f\"Train Accuracy: {train_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_set.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blemish_bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
