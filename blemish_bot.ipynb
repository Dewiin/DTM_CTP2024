{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BlemishBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from RealESRGAN import RealESRGAN\n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YuNet face detection model\n",
    "IMG_SIZE = 320\n",
    "yunet_path = 'models/face_detection_yunet_2023mar.onnx'\n",
    "yunet_face_detector = cv2.FaceDetectorYN_create(yunet_path, \"\", (IMG_SIZE, IMG_SIZE), score_threshold=0.5)\n",
    "\n",
    "# Load the YOLOv8 acne detection model\n",
    "yolo_path = 'models/acne_model.pt'\n",
    "yolo_acne_model = YOLO(yolo_path)\n",
    "\n",
    "# Load upscaling model\n",
    "# sr_model = dnn_superres.DnnSuperResImpl_create()\n",
    "# sr_model_path = 'SuperResDNN_x64/dnn_Models/FSRCNN_x4.pb'\n",
    "# sr_model.readModel(sr_model_path)\n",
    "# sr_model.setModel('fsrcnn', 4)\n",
    "\n",
    "device = torch.device('cpu')\n",
    "sr_model = RealESRGAN(device, scale=4)\n",
    "sr_model.load_weights('models/RealESRGAN_x4.pth', download=True)\n",
    "\n",
    "# Load classification model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_image_path = 'detection_test.webp'\n",
    "test_image_path = 'sample_inputs/detection_test_3.webp'\n",
    "test_image = cv2.imread(test_image_path)\n",
    "\n",
    "# Upscale an image\n",
    "# test_image = Image.open(test_image_path).convert(\"RGB\")\n",
    "# upscaled_image = model.predict(test_image)\n",
    "# upscaled_image.save(\"upscaled_image.jpg\")\n",
    "\n",
    "plt.imshow(test_image)\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Image\n",
    "- Initializes an image from an image_path string\n",
    "- Returns the RGB image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(image_path):\n",
    "  image = cv2.imread(image_path)\n",
    "  # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "  # Create a square padding\n",
    "  h, w = image.shape[:2]\n",
    "  new_size = max(h, w)\n",
    "  \n",
    "  padded_image = np.full((new_size, new_size, 3), (0, 0, 0), dtype=np.uint8)\n",
    "\n",
    "  # Calculate the position to place the original image\n",
    "  x_offset = (new_size - w) // 2\n",
    "  y_offset = (new_size - h) // 2\n",
    "\n",
    "  # Place the original image in the center\n",
    "  padded_image[y_offset:y_offset + h, x_offset:x_offset + w] = image\n",
    "\n",
    "  return padded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = prepare_image(test_image_path)\n",
    "plt.imshow(test_image)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face detection\n",
    "- Resize an image for the YuNet model\n",
    "- Check if only one face is detected\n",
    "- Returns a cropped image, where the face is isolated from the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detection_crop(image):\n",
    "  # resize image\n",
    "  resized_image = cv2.resize(image, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "  # detect face with YuNet\n",
    "  faces = yunet_face_detector.detect(resized_image)\n",
    "  \n",
    "  # assert that faces were detected\n",
    "  if faces[1] is None:\n",
    "    print(\"No face detected.\")\n",
    "    return None\n",
    "  \n",
    "  # assert that only one face is detected\n",
    "  elif len(faces[1]) > 1:\n",
    "    print(\"There can only be one face in the image\")\n",
    "    return None\n",
    "  \n",
    "  # crop the face\n",
    "  for face in faces[1]:\n",
    "    x,y,w,h = int(face[0]), int(face[1]), int(face[2]), int(face[3])\n",
    "\n",
    "    # ensure boundary boxes are within the image dimensions\n",
    "    x = max(0, x)\n",
    "    y = max(0, y)\n",
    "    w = min(w, IMG_SIZE - x)\n",
    "    h = min(h, IMG_SIZE - y)\n",
    "\n",
    "    cropped_image = resized_image[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing face_detection_crop function\n",
    "new_test_image = face_detection_crop(test_image)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(test_image)\n",
    "axs[0].set_title('Before')\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(new_test_image)\n",
    "axs[1].set_title('After')\n",
    "axs[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acne detection\n",
    "- detect acne regions\n",
    "- return acne regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acne_detection(image):\n",
    "  results = yolo_acne_model.predict(image, conf=0.3)\n",
    "\n",
    "  h,w = image.shape[:2]\n",
    "\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "  outputs = []\n",
    "  offset = 50\n",
    "  for result in results:\n",
    "    for box in result.boxes:\n",
    "      x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "      x1-=offset\n",
    "      x1 = max(0, x1)\n",
    "\n",
    "      x2+=offset\n",
    "      x2 = min(x2, w)\n",
    "\n",
    "      y1-=offset\n",
    "      y1 = max(0, y1)\n",
    "\n",
    "      y2+=offset\n",
    "      y2 = min(y2, h)\n",
    "\n",
    "      acne_region = image[y1:y2, x1:x2]\n",
    "      # sharpen_kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "      # acne_region = cv2.filter2D(acne_region, -1, sharpen_kernel)\n",
    "\n",
    "      acne_region = sr_model.predict(acne_region)\n",
    "\n",
    "      outputs.append(acne_region)\n",
    "\n",
    "  return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acne_detection_rect(image):\n",
    "  results = yolo_acne_model.predict(image, conf=0.3, iou=0.3, max_det=10)\n",
    "\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "  offset = 10\n",
    "  for result in results:\n",
    "    for box in result.boxes:\n",
    "      x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "      x1-=offset\n",
    "      x2+=offset\n",
    "      y1-=offset\n",
    "      y2+=offset\n",
    "      \n",
    "      cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = acne_detection_rect(new_test_image)\n",
    "plt.imshow(result)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "outputs = acne_detection(new_test_image)\n",
    "k = 0\n",
    "\n",
    "nrows = int(len(outputs)/3) + 1\n",
    "ncols = 3\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(9, 3*nrows))\n",
    "\n",
    "for i in range(0, nrows):\n",
    "  for j in range(0, ncols):\n",
    "    if k < len(outputs):\n",
    "      axs[i][j].imshow(outputs[k])\n",
    "      axs[i][j].axis('off')\n",
    "      k+=1\n",
    "    else:\n",
    "      axs[i][j].axis('off')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# YOLOv8 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cv2.imread('datasets/kaggle-acne/test/images/acne-5_jpeg.rf.2d6671715f0149df7b494c4d3f12a98b.jpg')\n",
    "check = yolo_acne_model.predict(result, conf=0.3)\n",
    "check[0].boxes\n",
    "\n",
    "for r in check:\n",
    "    boxes = r.boxes  # Bounding boxes\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])  # Get bounding box coordinates\n",
    "        \n",
    "        # Optionally, draw bounding boxes on the image or process further\n",
    "        cv2.rectangle(result, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)\n",
    "\n",
    "result = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(result)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blemishbot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
